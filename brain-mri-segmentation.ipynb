{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Preparation","metadata":{}},{"cell_type":"markdown","source":"**Imports**","metadata":{}},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport seaborn as sns\nsns.set()\nimport os\nimport glob\nimport time\nfrom tqdm import tqdm\nimport cv2\nimport matplotlib.pyplot as plt\nfrom mpl_toolkits.axes_grid1 import ImageGrid\nfrom sklearn.model_selection import train_test_split\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torchvision import transforms as T\nimport albumentations as A\n\nprint('Imports Complete')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-01-15T18:18:37.136707Z","iopub.execute_input":"2022-01-15T18:18:37.137288Z","iopub.status.idle":"2022-01-15T18:18:41.218304Z","shell.execute_reply.started":"2022-01-15T18:18:37.137191Z","shell.execute_reply":"2022-01-15T18:18:41.217285Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"**Setup**","metadata":{}},{"cell_type":"code","source":"ROOT_PATH = '../input/lgg-mri-segmentation/kaggle_3m/'\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\ndevice","metadata":{"execution":{"iopub.status.busy":"2022-01-15T18:18:41.220222Z","iopub.execute_input":"2022-01-15T18:18:41.220705Z","iopub.status.idle":"2022-01-15T18:18:41.274369Z","shell.execute_reply.started":"2022-01-15T18:18:41.220666Z","shell.execute_reply":"2022-01-15T18:18:41.273683Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"# Exploratory Data Analysis","metadata":{}},{"cell_type":"markdown","source":"**Creating DataFrame**","metadata":{}},{"cell_type":"code","source":"mask_files = glob.glob(ROOT_PATH + '*/*_mask*')\nimage_files = [f.replace('_mask', '') for f in mask_files]\n\nprint(len(mask_files), len(image_files))","metadata":{"execution":{"iopub.status.busy":"2022-01-15T18:18:41.275756Z","iopub.execute_input":"2022-01-15T18:18:41.276242Z","iopub.status.idle":"2022-01-15T18:18:41.948066Z","shell.execute_reply.started":"2022-01-15T18:18:41.276202Z","shell.execute_reply":"2022-01-15T18:18:41.946658Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# function that sets diagnosis based on image matrix values of the mask\ndef diagnosis(mask_path):\n   return 1 if np.max(cv2.imread(mask_path)) > 0 else 0\n\ndf = pd.DataFrame({\"image_path\": image_files,\n                   \"mask_path\": mask_files,\n                   \"diagnosis\": [diagnosis(m) for m in mask_files]})\n\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2022-01-15T18:18:41.950059Z","iopub.execute_input":"2022-01-15T18:18:41.950936Z","iopub.status.idle":"2022-01-15T18:19:02.357588Z","shell.execute_reply.started":"2022-01-15T18:18:41.950898Z","shell.execute_reply":"2022-01-15T18:19:02.356870Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"df.info()","metadata":{"execution":{"iopub.status.busy":"2022-01-15T18:19:02.358706Z","iopub.execute_input":"2022-01-15T18:19:02.358959Z","iopub.status.idle":"2022-01-15T18:19:02.384509Z","shell.execute_reply.started":"2022-01-15T18:19:02.358924Z","shell.execute_reply":"2022-01-15T18:19:02.383786Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"df.shape","metadata":{"execution":{"iopub.status.busy":"2022-01-15T18:19:02.385903Z","iopub.execute_input":"2022-01-15T18:19:02.386255Z","iopub.status.idle":"2022-01-15T18:19:02.394582Z","shell.execute_reply.started":"2022-01-15T18:19:02.386218Z","shell.execute_reply":"2022-01-15T18:19:02.392876Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"**Plotting data distribution**","metadata":{}},{"cell_type":"code","source":"ax = df['diagnosis'].value_counts().plot(kind='bar', figsize=(5,3), color=['blue', 'red'])\nax.set_title('Data Distribution')\nax.set_ylabel('Images')\nax.set_xticklabels(['No Tumor', 'Tumor'], rotation=0)\nfor i, rows in enumerate(df['diagnosis'].value_counts().values):\n    ax.annotate(int(rows), xy=(i, rows-200), ha='center', fontweight='bold')","metadata":{"execution":{"iopub.status.busy":"2022-01-15T18:19:02.395902Z","iopub.execute_input":"2022-01-15T18:19:02.396219Z","iopub.status.idle":"2022-01-15T18:19:02.643398Z","shell.execute_reply.started":"2022-01-15T18:19:02.396181Z","shell.execute_reply":"2022-01-15T18:19:02.642492Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"**Visualising images negative for tumor**","metadata":{}},{"cell_type":"code","source":"IMG_SIZE = 521\nimages = []\ndf_negative = df[df['diagnosis']==0].sample(5).values\nfor data in df_negative:\n    img = cv2.resize(cv2.imread(data[0]), (IMG_SIZE, IMG_SIZE))\n    images.append(img)\n    \nimages = np.hstack(np.array(images))\n\nfig = plt.figure(figsize=(25,25))\ngrid = ImageGrid(fig, 111, nrows_ncols=(1,1), axes_pad=0.5)\n\ngrid[0].imshow(images)\ngrid[0].set_title('Images')\ngrid[0].axis('off')","metadata":{"execution":{"iopub.status.busy":"2022-01-15T18:19:02.644987Z","iopub.execute_input":"2022-01-15T18:19:02.645247Z","iopub.status.idle":"2022-01-15T18:19:03.399215Z","shell.execute_reply.started":"2022-01-15T18:19:02.645212Z","shell.execute_reply":"2022-01-15T18:19:03.398488Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"**Visualising images with masks positive for tumor**","metadata":{}},{"cell_type":"code","source":"images = []\nmasks = []\ndf_positive = df[df['diagnosis']==1].sample(5).values\nfor data in df_positive:\n    img = cv2.resize(cv2.imread(data[0]), (IMG_SIZE, IMG_SIZE))\n    mask = cv2.resize(cv2.imread(data[1]), (IMG_SIZE, IMG_SIZE))\n    images.append(img)\n    masks.append(mask)\n\nimages = np.hstack(np.array(images))\nmasks = np.hstack(np.array(masks))\n\nfig = plt.figure(figsize=(25,25))\ngrid = ImageGrid(fig, 111, nrows_ncols=(3,1), axes_pad=0.5)\n\ngrid[0].imshow(images)\ngrid[0].set_title('Images')\ngrid[0].axis('off')\ngrid[1].imshow(masks)\ngrid[1].set_title('Masks')\ngrid[1].axis('off')\ngrid[2].imshow(images)\ngrid[2].imshow(masks, alpha=0.4)\ngrid[2].set_title('Images with masks')\ngrid[2].axis('off')","metadata":{"execution":{"iopub.status.busy":"2022-01-15T18:19:03.400636Z","iopub.execute_input":"2022-01-15T18:19:03.401073Z","iopub.status.idle":"2022-01-15T18:19:05.074198Z","shell.execute_reply.started":"2022-01-15T18:19:03.401028Z","shell.execute_reply":"2022-01-15T18:19:05.071452Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"# Data Generation and Augmentation","metadata":{}},{"cell_type":"markdown","source":"**Splitting data into train, val, test set**","metadata":{}},{"cell_type":"code","source":"train_df, val_df = train_test_split(df, stratify=df['diagnosis'], test_size=0.30)\nval_df, test_df = train_test_split(val_df, stratify=val_df['diagnosis'], test_size=0.5)\ntrain_df = train_df.reset_index(drop=True)\ntest_df = test_df.reset_index(drop=True)\nval_df = val_df.reset_index(drop=True)\n\nprint(\"Train: {}\\nVal: {}\\nTest: {}\".format(train_df.shape, val_df.shape, test_df.shape))","metadata":{"execution":{"iopub.status.busy":"2022-01-15T18:19:05.076814Z","iopub.execute_input":"2022-01-15T18:19:05.077611Z","iopub.status.idle":"2022-01-15T18:19:05.098347Z","shell.execute_reply.started":"2022-01-15T18:19:05.077572Z","shell.execute_reply":"2022-01-15T18:19:05.097686Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots(1,3,figsize=(20,5))\n\nsns.countplot(train_df.diagnosis, palette=\"Set1\", ax=ax[0])\nax[0].set_title('Train')\nax[0].set_ylabel('Images')\nax[0].set_xticklabels(['No Tumor', 'Tumor'], rotation=0)\nfor i, rows in enumerate(train_df['diagnosis'].value_counts().values):\n    ax[0].annotate(int(rows), xy=(i, rows), ha='center', fontweight='bold')\n\nsns.countplot(val_df.diagnosis, palette=\"Set2\", ax=ax[1])\nax[1].set_title('Val')\nax[1].set_ylabel('Images')\nax[1].set_xticklabels(['No Tumor', 'Tumor'], rotation=0)\nfor i, rows in enumerate(val_df['diagnosis'].value_counts().values):\n    ax[1].annotate(int(rows), xy=(i, rows), ha='center', fontweight='bold')\n\nsns.countplot(test_df.diagnosis, palette=\"Set3\", ax=ax[2])\nax[2].set_title('Test')\nax[2].set_ylabel('Images')\nax[2].set_xticklabels(['No Tumor', 'Tumor'], rotation=0)\nfor i, rows in enumerate(test_df['diagnosis'].value_counts().values):\n    ax[2].annotate(int(rows), xy=(i, rows), ha='center', fontweight='bold')","metadata":{"execution":{"iopub.status.busy":"2022-01-15T18:19:05.099576Z","iopub.execute_input":"2022-01-15T18:19:05.102187Z","iopub.status.idle":"2022-01-15T18:19:05.570295Z","shell.execute_reply.started":"2022-01-15T18:19:05.102147Z","shell.execute_reply":"2022-01-15T18:19:05.569651Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# function to view images after augmentation\ndef show_aug(inputs, nrows=5, ncols=5, image=True):\n    plt.figure(figsize=(10, 10))\n    plt.subplots_adjust(wspace=0., hspace=0.)\n    i = 0\n    if len(inputs) > 25:\n        inputs = inputs[:25]\n        \n    for idx in range(len(inputs)):\n        if image is True:           \n            img = inputs[idx].numpy().transpose(1,2,0)\n            mean = [0.485, 0.456, 0.406]\n            std = [0.229, 0.224, 0.225] \n            img = (img * std + mean).astype(np.float32)\n        else:\n            img = inputs[idx].numpy().astype(np.float32)\n            img = img[0,:,:]\n        plt.subplot(nrows, ncols, i+1)\n        plt.imshow(img); \n        plt.axis('off')\n        i += 1\n    return plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-01-15T18:19:05.571568Z","iopub.execute_input":"2022-01-15T18:19:05.573164Z","iopub.status.idle":"2022-01-15T18:19:05.581724Z","shell.execute_reply.started":"2022-01-15T18:19:05.573119Z","shell.execute_reply":"2022-01-15T18:19:05.581000Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"**Defining Dataset**","metadata":{}},{"cell_type":"code","source":"class MRIBrainDataset(torch.utils.data.Dataset):\n    def __init__(self, df, transform=None):\n        self.df = df\n        self.transform = transform\n    def __len__(self):\n        return len(self.df)\n    def __getitem__(self, idx):\n        image = cv2.imread(self.df.iloc[idx, 0])\n        image = np.array(image)/255.\n        mask = cv2.imread(self.df.iloc[idx, 1], 0)\n        mask = np.array(mask)/255.\n        \n        if self.transform is not None:\n            aug = self.transform(image=image, mask=mask)\n            image = aug['image']\n            mask = aug['mask']\n            \n        image = image.transpose((2,0,1))\n        image = torch.from_numpy(image).type(torch.float32)\n        image = T.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))(image)\n        mask = np.expand_dims(mask, axis=-1).transpose((2,0,1))\n        mask = torch.from_numpy(mask).type(torch.float32)\n        \n        return image, mask","metadata":{"execution":{"iopub.status.busy":"2022-01-15T18:19:05.583146Z","iopub.execute_input":"2022-01-15T18:19:05.583419Z","iopub.status.idle":"2022-01-15T18:19:05.595469Z","shell.execute_reply.started":"2022-01-15T18:19:05.583381Z","shell.execute_reply":"2022-01-15T18:19:05.594716Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"**Applying transformations**","metadata":{}},{"cell_type":"code","source":"train_transform = A.Compose([\n    A.Resize(width=128, height=128, p=1.0),\n    A.HorizontalFlip(p=0.5),\n    A.VerticalFlip(p=0.5),\n    A.RandomRotate90(p=0.5),\n    A.ShiftScaleRotate(shift_limit=0.01, scale_limit=0.04, rotate_limit=0, p=0.25),\n])\nval_transform = A.Compose([\n    A.Resize(width=128, height=128, p=1.0),\n    A.HorizontalFlip(p=0.5),\n    A.VerticalFlip(p=0.5),\n    A.RandomRotate90(p=0.5),\n    A.ShiftScaleRotate(shift_limit=0.01, scale_limit=0.04, rotate_limit=0, p=0.25),\n])\ntest_transform = A.Compose([\n    A.Resize(width=128, height=128, p=1.0),\n    A.HorizontalFlip(p=0.5),\n    A.VerticalFlip(p=0.5),\n    A.RandomRotate90(p=0.5),\n    A.ShiftScaleRotate(shift_limit=0.01, scale_limit=0.04, rotate_limit=0, p=0.25),\n])","metadata":{"execution":{"iopub.status.busy":"2022-01-15T18:19:05.597059Z","iopub.execute_input":"2022-01-15T18:19:05.597423Z","iopub.status.idle":"2022-01-15T18:19:05.608615Z","shell.execute_reply.started":"2022-01-15T18:19:05.597330Z","shell.execute_reply":"2022-01-15T18:19:05.607717Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"**Creating dataset and dataloader**","metadata":{}},{"cell_type":"code","source":"train_dataset = MRIBrainDataset(train_df, train_transform)\ntrain_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=26, shuffle=True, num_workers=2)\n\nval_dataset = MRIBrainDataset(val_df, val_transform)\nval_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=26, shuffle=True, num_workers=2)\n\ntest_dataset = MRIBrainDataset(test_df, test_transform)\ntest_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=26, shuffle=True, num_workers=2)","metadata":{"execution":{"iopub.status.busy":"2022-01-15T18:19:05.610196Z","iopub.execute_input":"2022-01-15T18:19:05.610591Z","iopub.status.idle":"2022-01-15T18:19:05.618268Z","shell.execute_reply.started":"2022-01-15T18:19:05.610555Z","shell.execute_reply":"2022-01-15T18:19:05.617186Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"images, masks = next(iter(train_dataloader))\nprint(images.shape)\nprint(masks.shape)\nshow_aug(images)\nshow_aug(masks, image=False)","metadata":{"execution":{"iopub.status.busy":"2022-01-15T18:19:05.619751Z","iopub.execute_input":"2022-01-15T18:19:05.620363Z","iopub.status.idle":"2022-01-15T18:19:10.158534Z","shell.execute_reply.started":"2022-01-15T18:19:05.620321Z","shell.execute_reply":"2022-01-15T18:19:10.157697Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"# Defining Model","metadata":{}},{"cell_type":"markdown","source":"Using Unet model","metadata":{}},{"cell_type":"code","source":"class DoubleConv(nn.Module):\n    def __init__(self, in_channels, out_channels, mid_channels=None):\n        super().__init__()\n        if not mid_channels:\n            mid_channels = out_channels\n        self.double_conv = nn.Sequential(\n            nn.Conv2d(in_channels, mid_channels, kernel_size=3, padding=1),\n            nn.BatchNorm2d(mid_channels),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(mid_channels, out_channels, kernel_size=3, padding=1),\n            nn.BatchNorm2d(out_channels),\n            nn.ReLU(inplace=True))\n    def forward(self, x):\n        return self.double_conv(x)\n    \nclass Down(nn.Module):\n    def __init__(self, in_channels, out_channels):\n        super().__init__()\n        self.maxpool_conv = nn.Sequential(\n            nn.MaxPool2d(2),\n            DoubleConv(in_channels, out_channels))\n    def forward(self, x):\n        return self.maxpool_conv(x)\n    \nclass Up(nn.Module):\n    def __init__(self, in_channels, out_channels, bilinear=True):\n        super().__init__()\n        if bilinear:\n            self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n            self.conv = DoubleConv(in_channels, out_channels, in_channels//2)\n        else:\n            self.up = nn.ConvTranspose2d(in_channels, in_channels//2, kernel_size=2, stride=2)\n            self.conv = DoubleConv(in_channels, out_channels)\n    def forward(self, x1, x2):\n        x1 = self.up(x1)\n        diffY = x2.size()[2] - x1.size()[2]\n        diffX = x2.size()[3] - x1.size()[3]\n        \n        x1 = F.pad(x1, [diffX//2, diffX-diffX//2,\n                        diffY//2, diffY-diffY//2])\n        x = torch.cat([x2, x1], dim=1)\n        return self.conv(x)\n\nclass OutConv(nn.Module):\n    def __init__(self, in_channels, out_channels):\n        super(OutConv, self).__init__()\n        self.conv = nn.Sequential(\n            nn.Conv2d(in_channels, out_channels, kernel_size=1),\n            nn.Sigmoid())\n    def forward(self, x):\n        return self.conv(x)","metadata":{"execution":{"iopub.status.busy":"2022-01-15T18:19:10.161426Z","iopub.execute_input":"2022-01-15T18:19:10.161637Z","iopub.status.idle":"2022-01-15T18:19:10.176492Z","shell.execute_reply.started":"2022-01-15T18:19:10.161611Z","shell.execute_reply":"2022-01-15T18:19:10.175745Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"class UNet(nn.Module):\n    def __init__(self, n_channels, n_classes, bilinear=True):\n        super(UNet, self).__init__()\n        self.n_channels = n_channels\n        self.n_classes = n_classes\n        self.bilinear = bilinear\n        \n        self.inc = DoubleConv(n_channels, 64)\n        self.down1 = Down(64, 128)\n        self.down2 = Down(128, 256)\n        self.down3 = Down(256, 512)\n        factor = 2 if bilinear else 1\n        self.down4 = Down(512, 1024//factor)\n        self.up1 = Up(1024, 512//factor, bilinear)\n        self.up2 = Up(512, 256//factor, bilinear)        \n        self.up3 = Up(256, 128//factor, bilinear)        \n        self.up4 = Up(128, 64, bilinear)        \n        self.outc = OutConv(64, n_classes)\n    \n    def forward(self, x):\n        x1 = self.inc(x)\n        x2 = self.down1(x1)\n        x3 = self.down2(x2)\n        x4 = self.down3(x3)\n        x5 = self.down4(x4)\n        x = self.up1(x5, x4)\n        x = self.up2(x, x3)\n        x = self.up3(x, x2)\n        x = self.up4(x, x1)\n        logits = self.outc(x)\n        return logits","metadata":{"execution":{"iopub.status.busy":"2022-01-15T18:19:10.178072Z","iopub.execute_input":"2022-01-15T18:19:10.178348Z","iopub.status.idle":"2022-01-15T18:19:10.189330Z","shell.execute_reply.started":"2022-01-15T18:19:10.178311Z","shell.execute_reply":"2022-01-15T18:19:10.188655Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"model = UNet(3, 1).to(device)\nout = model(torch.randn(1, 3, 256, 256).to(device))\nprint(out.shape)","metadata":{"execution":{"iopub.status.busy":"2022-01-15T18:19:10.190668Z","iopub.execute_input":"2022-01-15T18:19:10.191366Z","iopub.status.idle":"2022-01-15T18:19:18.174652Z","shell.execute_reply.started":"2022-01-15T18:19:10.191328Z","shell.execute_reply":"2022-01-15T18:19:18.173884Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":"# Metric and Loss","metadata":{}},{"cell_type":"code","source":"def dice_coef_metric(pred, label):\n    intersection = 2.0 * (pred * label).sum()\n    union = pred.sum() + label.sum()\n    if pred.sum() == 0 and label.sum() == 0:\n        return 1.\n    return intersection / union\ndef dice_coef_loss(pred, label):\n    smooth = 1.0\n    intersection = 2.0 * (pred * label).sum() + smooth\n    union = pred.sum() + label.sum() + smooth\n    return 1 - (intersection / union)\ndef bce_dice_loss(pred, label):\n    dice_loss = dice_coef_loss(pred, label)\n    bce_loss = nn.BCELoss()(pred, label)\n    return dice_loss + bce_loss","metadata":{"execution":{"iopub.status.busy":"2022-01-15T18:19:18.175892Z","iopub.execute_input":"2022-01-15T18:19:18.176244Z","iopub.status.idle":"2022-01-15T18:19:18.183579Z","shell.execute_reply.started":"2022-01-15T18:19:18.176203Z","shell.execute_reply":"2022-01-15T18:19:18.182714Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":"# Train model","metadata":{}},{"cell_type":"code","source":"def compute_iou(model, loader, threshold=0.3):\n    valloss = 0\n    with torch.no_grad():\n        for step, (data, target) in enumerate(loader):\n            data = data.to(device)\n            target = target.to(device)\n\n            outputs = model(data)\n            out_cut = np.copy(outputs.data.cpu().numpy())\n            out_cut[np.nonzero(out_cut < threshold)] = 0.0\n            out_cut[np.nonzero(out_cut >= threshold)] = 1.0\n\n            loss = dice_coef_metric(out_cut, target.data.cpu().numpy())\n            valloss += loss\n\n    return valloss / step","metadata":{"execution":{"iopub.status.busy":"2022-01-15T18:19:18.184725Z","iopub.execute_input":"2022-01-15T18:19:18.185498Z","iopub.status.idle":"2022-01-15T18:19:18.195388Z","shell.execute_reply.started":"2022-01-15T18:19:18.185458Z","shell.execute_reply":"2022-01-15T18:19:18.194448Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"def train_model(train_loader, val_loader, loss_func, optimizer, scheduler, num_epochs):\n    loss_history = []\n    train_history = []\n    val_history = []\n    \n    for epoch in range(num_epochs):\n        model.train()\n        \n        losses = []\n        train_iou = []\n        \n        for i, (image, mask) in enumerate(tqdm(train_loader)):\n            image = image.to(device)\n            mask = mask.to(device)\n            outputs = model(image)\n            out_cut = np.copy(outputs.data.cpu().numpy())\n            out_cut[np.nonzero(out_cut < 0.5)] = 0.0\n            out_cut[np.nonzero(out_cut >= 0.5)] = 1.0            \n            \n            train_dice = dice_coef_metric(out_cut, mask.data.cpu().numpy())\n            loss = loss_func(outputs, mask)\n            losses.append(loss.item())\n            train_iou.append(train_dice)\n            \n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n                \n        val_mean_iou = compute_iou(model, val_loader)\n        scheduler.step(val_mean_iou)\n        loss_history.append(np.array(losses).mean())\n        train_history.append(np.array(train_iou).mean())\n        val_history.append(val_mean_iou)\n        \n        print('Epoch : {}/{}'.format(epoch+1, num_epochs))\n        print('loss: {:.3f} - dice_coef: {:.3f} - val_dice_coef: {:.3f}'.format(np.array(losses).mean(),\n                                                                               np.array(train_iou).mean(),\n                                                                               val_mean_iou))\n    return loss_history, train_history, val_history","metadata":{"execution":{"iopub.status.busy":"2022-01-15T18:19:18.196604Z","iopub.execute_input":"2022-01-15T18:19:18.197459Z","iopub.status.idle":"2022-01-15T18:19:18.212703Z","shell.execute_reply.started":"2022-01-15T18:19:18.197344Z","shell.execute_reply":"2022-01-15T18:19:18.211879Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\nscheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'max', patience=3)\nnum_epochs = 50\nloss_history, train_history, val_history = train_model(train_dataloader, val_dataloader, bce_dice_loss, optimizer, scheduler, num_epochs)","metadata":{"execution":{"iopub.status.busy":"2022-01-15T18:24:18.087947Z","iopub.execute_input":"2022-01-15T18:24:18.088724Z","iopub.status.idle":"2022-01-15T18:47:07.468541Z","shell.execute_reply.started":"2022-01-15T18:24:18.088668Z","shell.execute_reply":"2022-01-15T18:47:07.467563Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"markdown","source":"# Training History","metadata":{}},{"cell_type":"code","source":"def plot_model_history(model_name, train_history, val_history, num_epochs):\n    \n    x = np.arange(num_epochs)\n    fig = plt.figure(figsize=(10, 6))\n    plt.plot(x, train_history, label='train dice', lw=3, c=\"b\")\n    plt.plot(x, val_history, label='validation dice', lw=3, c=\"r\")\n\n    plt.title(f\"{model_name}\", fontsize=15)\n    plt.legend(fontsize=12)\n    plt.xlabel(\"Epoch\", fontsize=15)\n    plt.ylabel(\"Dice\", fontsize=15)\n\n    plt.show()\n    \nplot_model_history('UNet', train_history, val_history, num_epochs)","metadata":{"execution":{"iopub.status.busy":"2022-01-15T18:50:34.074004Z","iopub.execute_input":"2022-01-15T18:50:34.074800Z","iopub.status.idle":"2022-01-15T18:50:34.359516Z","shell.execute_reply.started":"2022-01-15T18:50:34.074756Z","shell.execute_reply":"2022-01-15T18:50:34.358812Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"markdown","source":"# Testing\n","metadata":{}},{"cell_type":"code","source":"test_iou = compute_iou(model, test_dataloader)\nprint(\"Mean IoU: {:.3f}%\".format(100*test_iou))","metadata":{"execution":{"iopub.status.busy":"2022-01-15T18:51:24.882649Z","iopub.execute_input":"2022-01-15T18:51:24.882928Z","iopub.status.idle":"2022-01-15T18:51:30.283426Z","shell.execute_reply.started":"2022-01-15T18:51:24.882897Z","shell.execute_reply":"2022-01-15T18:51:30.282523Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"test_sample = test_df[test_df[\"diagnosis\"] == 1].sample(1).values[0]\nimage = cv2.resize(cv2.imread(test_sample[0]), (128, 128))\nmask = cv2.resize(cv2.imread(test_sample[1]), (128, 128))\n\n# pred\npred = torch.tensor(image.astype(np.float32) / 255.).unsqueeze(0).permute(0,3,1,2)\npred = T.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))(pred)\npred = model(pred.to(device))\npred = pred.detach().cpu().numpy()[0,0,:,:]\n\npred_t = np.copy(pred)\npred_t[np.nonzero(pred_t < 0.3)] = 0.0\npred_t[np.nonzero(pred_t >= 0.3)] = 255.\npred_t = pred_t.astype(\"uint8\")\n\n# plot\nfig, ax = plt.subplots(nrows=2,  ncols=2, figsize=(10, 10))\n\nax[0, 0].imshow(image)\nax[0, 0].set_title(\"image\")\nax[0, 1].imshow(mask)\nax[0, 1].set_title(\"mask\")\nax[1, 0].imshow(pred)\nax[1, 0].set_title(\"prediction\")\nax[1, 1].imshow(pred_t)\nax[1, 1].set_title(\"prediction with threshold\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-01-15T19:22:41.003014Z","iopub.execute_input":"2022-01-15T19:22:41.003274Z","iopub.status.idle":"2022-01-15T19:22:41.746338Z","shell.execute_reply.started":"2022-01-15T19:22:41.003246Z","shell.execute_reply":"2022-01-15T19:22:41.745652Z"},"trusted":true},"execution_count":29,"outputs":[]}]}